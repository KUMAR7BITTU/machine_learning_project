{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' What is DataIngestionConfig in general ? The information of source data from where we have to collect the data \\nor\\nall the configuration required to access the data , that configuration we will specify in DataIngestionConfig . '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's define DataIngestionConfig\n",
    "\"\"\" What is DataIngestionConfig in general ? The information of source data from where we have to collect the data \n",
    "or\n",
    "all the configuration required to access the data , that configuration we will specify in DataIngestionConfig . \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 58, 489)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuple \n",
    "(33,58,489)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' If we provide name to each and every element of tuple then it is called namedtuple .\\nIn namedtuple, every element in the tuple will be some name . Tuple is immutable .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" If we provide name to each and every element of tuple then it is called namedtuple .\n",
    "In namedtuple, every element in the tuple will be some name . Tuple is immutable .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' We all know that tuple is use to store information and we are going to use namedtuple where we will give name for each value in the tuple .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will try to give name to every element in the tupple .\n",
    "# We will name a tuple as DataIngestionConfig .\n",
    "\"\"\" We all know that tuple is use to store information and we are going to use namedtuple where we will give name for each value in the tuple .\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " The configurations that we need to specify in dataingestion component are mentioned below :-\n",
    " \n",
    "1. Download url\n",
    "2. Download folder (compressed file)\n",
    "3. Extract folder (Extracted file)\n",
    "4. Train dataset folder \n",
    "5. Test dataset folder \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# namedtuple function will take first parameter as name and we have to give same name . The second parameter should be list which can contain any number of element .\n",
    "DataIngestionConfig = namedtuple(\"DataIngestionConfig\",[\"dataset_download_url\",\"tgz_download_dir\",\"raw_data_dir\",\"ingested_train_dir\",\"ingested_test_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first element in tuple will be url for dataset . Next whenever we will download any file or folder , it will be get downloaded in download folder and the file extension is tgz . This will be our second element . tgz is a compress file .  The third element contain the information where we will extract zip file(zip file which was downloaded in download folder ). The third element will be train dataset folder and fourth element will be test dataset folder .\n",
    "\n",
    "\n",
    "# The first element will store location of url where we will download our file / download and second element will store the location where our file / folder will be downloaded .The file which we be downloaded in download folder will raw file or compress file ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataIngestionConfig is a entity here .\n",
    "data_ingestion_config = DataIngestionConfig(dataset_download_url=\"adsfs\",tgz_download_dir=\"sfsdgg\",raw_data_dir=\"ethssd\",ingested_train_dir=\"nsierg\",ingested_test_dir=\"soerd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataIngestionConfig(dataset_download_url='adsfs', tgz_download_dir='sfsdgg', raw_data_dir='ethssd', ingested_train_dir='nsierg', ingested_test_dir='soerd')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the information that  will be  contain in data_ingestion_config is mentioned below\n",
    "data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have not used dictionary here because dictionary is mutable . So, the configuration information can be changed . But tuple is immutable . When we are passing information and we don't it to change then we use namedtuple otherwise we  dictionary ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gsdgd', 'ddsgdsg', 'xkdood', 'wotubu', 'afaoogs')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"gsdgd\",\"ddsgdsg\",\"xkdood\",\"wotubu\",\"afaoogs\")\n",
    "# If we use normal tuple to store configuration information then we can't get proper understanding of which element is for which purpose . So, that'sway we have used namedtuple . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to install PyYAML library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get current directory\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\project_ml\\\\machine_learning_project\\\\notebook'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, above mentioned location is my current location ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change directory use below mentioned code\n",
    "os.chdir(\"c:\\\\project_ml\\\\machine_learning_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\project_ml\\\\machine_learning_project'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.dockerignore',\n",
       " '.git',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " 'app.py',\n",
       " 'config',\n",
       " 'Dockerfile',\n",
       " 'housing',\n",
       " 'Include',\n",
       " 'Lib',\n",
       " 'LICENSE',\n",
       " 'notebook',\n",
       " 'pyvenv.cfg',\n",
       " 'README.md',\n",
       " 'requirements.txt',\n",
       " 'setup.py',\n",
       " 'study',\n",
       " 'venv']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suppose if we want to see folders and files name available in current directory then :-\n",
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use dot then it will point to current directory ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.yaml']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose if we want to see what folder/file do we have in this config folder then:-\n",
    "os.listdir(\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config file path\n",
    "config_file_path = \"config/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use file path always use os.path.join\n",
    "config_file_path = os.path.join(\"config\",\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config\\\\config.yaml'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above code will create file path based on operating system. So, we will not face any system .\n",
    "config_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, we have just create a file path for config.yaml file  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check whether our file (or file path ) exist or not .\n",
    "os.path.exists(config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's means file is available ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\project_ml\\\\machine_learning_project'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read a yaml file .\n",
    "config_info = None\n",
    "with open(config_file_path,\"rb\") as yaml_file:\n",
    "    config_info = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_pipeline_config': {'pipeline_name': 'housing',\n",
       "  'artifact_dir': 'artifact'},\n",
       " 'data_ingestion_config': {'dataset_download_url': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz',\n",
       "  'raw_data_dir': 'raw_data',\n",
       "  'tgz_download_dir': 'tgz_data',\n",
       "  'ingested_dir': 'ingested_data',\n",
       "  'ingested_train_dir': 'train',\n",
       "  'ingested_test_dir': 'test'},\n",
       " 'data_validation_config': {'schema_dir': 'config',\n",
       "  'schema_file_name': 'schema.yaml',\n",
       "  'report_file_name': 'report.json',\n",
       "  'report_page_file_name': 'report.html'},\n",
       " 'data_transformation_config': {'add_bedroom_per_room': True,\n",
       "  'transformed_dir': 'transformed_data',\n",
       "  'transformed_train_dir': 'train',\n",
       "  'transformed_test_dir': 'test',\n",
       "  'preprocessing_dir': 'preprocessed',\n",
       "  'preprocessed_object_file_name': 'preprocessed.pkl'},\n",
       " 'model_trainer_config': {'trained_model_dir': 'trained_model',\n",
       "  'model_file_name': 'model.pkl',\n",
       "  'base_accuracy': 0.6,\n",
       "  'model_config_dir': 'config',\n",
       "  'model_config_file_name': 'model.yaml'},\n",
       " 'model_evaluation_config': {'model_evaluation_file_name': 'model_evaluation.yaml'},\n",
       " 'model_pusher_config': {'model_export_dir': 'saved_models'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will basically give dictionary \n",
    "config_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_download_url': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz',\n",
       " 'raw_data_dir': 'raw_data',\n",
       " 'tgz_download_dir': 'tgz_data',\n",
       " 'ingested_dir': 'ingested_data',\n",
       " 'ingested_train_dir': 'train',\n",
       " 'ingested_test_dir': 'test'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose if we want to read available in data_ingestion_config:-\n",
    "config_info[\"data_ingestion_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, we are going to create a function which will read yaml file and that function will return dictionary .\n",
    "def read_yaml_file(file_path:str)->dict:\n",
    "    \"\"\" \n",
    "    Read the yaml file and returns the contents as a dictionary.file_path: str\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path,'rb') as yaml_file:\n",
    "            return yaml.safe_load(yaml_file)\n",
    "    except Exception as e:\n",
    "        raise e \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_pipeline_config': {'pipeline_name': 'housing',\n",
       "  'artifact_dir': 'artifact'},\n",
       " 'data_ingestion_config': {'dataset_download_url': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz',\n",
       "  'raw_data_dir': 'raw_data',\n",
       "  'tgz_download_dir': 'tgz_data',\n",
       "  'ingested_dir': 'ingested_data',\n",
       "  'ingested_train_dir': 'train',\n",
       "  'ingested_test_dir': 'test'},\n",
       " 'data_validation_config': {'schema_dir': 'config',\n",
       "  'schema_file_name': 'schema.yaml',\n",
       "  'report_file_name': 'report.json',\n",
       "  'report_page_file_name': 'report.html'},\n",
       " 'data_transformation_config': {'add_bedroom_per_room': True,\n",
       "  'transformed_dir': 'transformed_data',\n",
       "  'transformed_train_dir': 'train',\n",
       "  'transformed_test_dir': 'test',\n",
       "  'preprocessing_dir': 'preprocessed',\n",
       "  'preprocessed_object_file_name': 'preprocessed.pkl'},\n",
       " 'model_trainer_config': {'trained_model_dir': 'trained_model',\n",
       "  'model_file_name': 'model.pkl',\n",
       "  'base_accuracy': 0.6,\n",
       "  'model_config_dir': 'config',\n",
       "  'model_config_file_name': 'model.yaml'},\n",
       " 'model_evaluation_config': {'model_evaluation_file_name': 'model_evaluation.yaml'},\n",
       " 'model_pusher_config': {'model_export_dir': 'saved_models'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to read config_file_path\n",
    "\n",
    "read_yaml_file(config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_yaml_file(config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_pipeline_config': {'pipeline_name': 'housing',\n",
       "  'artifact_dir': 'artifact'},\n",
       " 'data_ingestion_config': {'dataset_download_url': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz',\n",
       "  'raw_data_dir': 'raw_data',\n",
       "  'tgz_download_dir': 'tgz_data',\n",
       "  'ingested_dir': 'ingested_data',\n",
       "  'ingested_train_dir': 'train',\n",
       "  'ingested_test_dir': 'test'},\n",
       " 'data_validation_config': {'schema_dir': 'config',\n",
       "  'schema_file_name': 'schema.yaml',\n",
       "  'report_file_name': 'report.json',\n",
       "  'report_page_file_name': 'report.html'},\n",
       " 'data_transformation_config': {'add_bedroom_per_room': True,\n",
       "  'transformed_dir': 'transformed_data',\n",
       "  'transformed_train_dir': 'train',\n",
       "  'transformed_test_dir': 'test',\n",
       "  'preprocessing_dir': 'preprocessed',\n",
       "  'preprocessed_object_file_name': 'preprocessed.pkl'},\n",
       " 'model_trainer_config': {'trained_model_dir': 'trained_model',\n",
       "  'model_file_name': 'model.pkl',\n",
       "  'base_accuracy': 0.6,\n",
       "  'model_config_dir': 'config',\n",
       "  'model_config_file_name': 'model.yaml'},\n",
       " 'model_evaluation_config': {'model_evaluation_file_name': 'model_evaluation.yaml'},\n",
       " 'model_pusher_config': {'model_export_dir': 'saved_models'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.constant import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_pipeline_config'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_PIPELINE_CONFIG_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline_name': 'housing', 'artifact_dir': 'artifact'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[TRAINING_PIPELINE_CONFIG_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'housing'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[TRAINING_PIPELINE_CONFIG_KEY][TRAINING_PIPELINE_NAME_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline_config = config_info[TRAINING_PIPELINE_CONFIG_KEY]\n",
    "artifact_dir = os.path.join(ROOT_DIR, training_pipeline_config[TRAINING_PIPELINE_NAME_KEY], training_pipeline_config[TRAINING_PIPELINE_ARTIFACT_DIR_KEY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\project_ml\\\\machine_learning_project'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'housing'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_config[TRAINING_PIPELINE_NAME_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifact'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_config[TRAINING_PIPELINE_ARTIFACT_DIR_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\project_ml\\\\machine_learning_project\\\\housing\\\\artifact'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.config.configuration import configuartion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configuartion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingPipelineConfig(artifact_dir='c:\\\\project_ml\\\\machine_learning_project\\\\housing\\\\artifact')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.get_training_pipeline_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
